We evaluate the effectiveness of our OOV models on the WMT'14 English-to-French translation 
task. Translation quality is measured with the BLEU metric \cite{Papineni02bleu} on the newstest2014 test set (which has 3003 sentences).
%\footnote{\url{http://www.statmt.org/wmt14/translation-task.html}} 

\subsection{Training Data}

To be comparable with the results reported by previous work on neural machine translation systems
\cite{sutskever14,cho14,bog15}, we train our models on 
the same training data of 12M parallel sentences (348M French and 304M English words), obtained from \cite{wmt14_en_fr}. 
The 12M subset was selected 
from the full WMT'14 parallel corpora using the method proposed in \newcite{Axelrod:2011:DAV}.%\footnote{\url{http://www-lium.univ-lemans.fr/~schwenk/cslm_joint_paper/}.}

Due to the computationally intensive nature of the naive softmax,
we limit the French vocabulary (the {\it target} language) 
to the either the 40K or the 80K most frequent French words. On the {\it source} side, 
we can afford a much larger vocabulary, so we use the 200K most frequent English words. 
The model treats all other words as unknowns.\footnote{When the French vocabulary has 40K words, there are
on average 1.33 unknown words per sentence on the target side of the test set.}

We annotate our training data using the three schemes described in the previous section. The alignment 
is computed with the Berkeley aligner \cite{liang06alignment} using its default settings.
We discard sentence pairs in which the source or the target sentence exceed 100 tokens.

\subsection{Training Details}
\label{subsec:train_details}
Our training procedure and hyperparameter choices are similar to those used by
\newcite{sutskever14}. In more details, we train multi-layer deep LSTMs, each of which has 
1000 cells, with 1000 dimensional embeddings. Like \newcite{sutskever14}, 
we reverse the words in the source sentences which 
has been shown to improve LSTM memory utilization and results in better translations of long sentences. 
Our hyperparameters can be summarized as follows: (a) the parameters are initialized uniformly  
in [-0.08, 0.08] for 4-layer models and [-0.06, 0.06] for 6-layer models, (b) SGD has a fixed learning rate of 0.7, (c) we train for 8 epochs (after
5 epochs, we begin to halve the learning rate every 0.5 epoch), (d) the size of the mini-batch is 128, 
and (e) we rescale the normalized gradient to ensure that its norm does not
exceed 5 \cite{pascanu13}.

We also follow the GPU parallelization scheme proposed in \cite{sutskever14}, allowing us to  
reach a training speed of 5.4K words per second to train a depth-6 model with 200K source and 80K target vocabularies  
; whereas \newcite{sutskever14} achieved 6.3K words per 
second for a depth-4 models with 80K source and target vocabularies.
Training takes about 10-14 days on an 8-GPU machine.

\subsection{A note on BLEU scores}
We report BLEU scores based on both: (a) {\it detokenized} translations, i.e., WMT'14 style, to be comparable with results reported on the WMT website\footnote{\url{http://matrix.statmt.org/matrix}} and (b) {\it tokenized translations}, so as to be consistent with previous work \cite{cho14,bog15,wmt14_en_fr,sutskever14,jean15}.\footnote{The \texttt{tokenizer.perl} and \texttt{multi-bleu.pl} scripts are used to tokenize and score translations.}

The existing WMT'14 state-of-the-art system \cite{durrani-EtAl:2014:W14-33} achieves a detokenized BLEU score of 35.8 on 
the newstest2014 test set for English to French language pair (see Table~\ref{t:results_wmt}). In terms of the tokenized BLEU, its performance is 37.0 points (see Table~\ref{t:results}).
\begin{table}[tbh!]
\centering
\begin{tabular}{l|c}
\bf{System} & \bf{BLEU}\\
  \hline
Existing SOTA \cite{durrani-EtAl:2014:W14-33} & 35.8\\
%  \hline
%Ensemble of 8 LSTMs & 80K & 36M & \bestbleu{}\\
  \hline
Ensemble of 8 LSTMs + PosUnk  & {\bf \bestbleuunkwmt{}}\\
\end{tabular}
\caption[Detokenized BLEU on newstest2014]{{\bf Detokenized BLEU on newstest2014} -- translation results of the existing state-of-the-art system and our best system.}
\label{t:results_wmt}
\end{table}


\subsection{Main Results}
We compare our systems to others, including the current state-of-the-art MT system \cite{durrani-EtAl:2014:W14-33},
recent end-to-end neural systems, as well as phrase-based baselines with neural components.

The results shown in Table~\ref{t:results} demonstrate that our unknown word translation technique (in particular, the PosUnk model) significantly improves the translation quality for both the individual (non-ensemble) LSTM models and the ensemble models.\footnote{
For the 40K-vocabulary ensemble, we combine 5 models with 4 layers and 3 models
with 6 layers. For the 80K-vocabulary ensemble, we combine 3 models with 4
layers and 5 models with 6 layers. Two of the depth-6 models are regularized
with dropout, similar to \newcite{zaremba14} with the dropout probability set to 0.2.} 
For 40K-word vocabularies, the performance gains are in the range of 2.3-2.8 BLEU points. With larger vocabularies (80K), the performance gains are diminished, but our technique can still provide a nontrivial gains of 1.6-1.9 BLEU points. 

\begin{table*}[tbh!]
\centering
\resizebox{15cm}{!}{
\begin{tabular}{l|c|c|l}
\bf{System} & \bf{Vocab} & {\bf Corpus} & \bf{BLEU}\\
  \hline
State of the art in WMT'14 \cite{durrani-EtAl:2014:W14-33} & All & 36M & {\bf 37.0}\\
  \hline
\multicolumn{4}{c}{{\it Standard MT + neural components}}\\
  \hline
\newcite{wmt14_en_fr} -- neural language model & All & 12M & 33.3\\ % 
\newcite{cho14}-- phrase table neural features & All & 12M & 34.5\\ % 
\newcite{sutskever14} -- 5 LSTMs, reranking 1000-best lists & All & 12M & 36.5\\ %
  \hline
\multicolumn{4}{c}{{\it Existing end-to-end NMT systems}}\\
  \hline
\newcite{bog15} -- single gated RNN with search & 30K & 12M & 28.5\\
\newcite{sutskever14} -- 5 LSTMs & 80K & 12M & 34.8\\
\newcite{jean15} -- 8 gated RNNs with search + UNK replacement & 500K & 12M & 37.2\\
  \hline
\multicolumn{4}{c}{{\it Our end-to-end NMT systems }}\\
  \hline
Single LSTM with 4 layers  & 40K & 12M & 29.5\\ %(perplexity 4.69)
Single LSTM with 4 layers + PosUnk & 40K & 12M & 31.8 (+2.3) \\
Single LSTM with 6 layers & 40K & 12M & 30.4\\ %(perplexity 4.64) 
Single LSTM with 6 layers + PosUnk & 40K & 12M & 32.7 (+2.3) \\
Ensemble of 8 LSTMs & 40K & 12M & 34.1 \\
Ensemble of 8 LSTMs + PosUnk & 40K & 12M & 36.9 (+2.8)\\
  \hline
Single LSTM with 6 layers & 80K & 36M & 31.5\\ %(perplexity 4.64) 
Single LSTM with 6 layers + PosUnk & 80K & 36M & 33.1 (+1.6) \\
Ensemble of 8 LSTMs & 80K & 36M & \bestbleu{}\\
Ensemble of 8 LSTMs + PosUnk & 80K & 36M & {\bf \bestbleuunk{} (+\unkimp{})}\\
\end{tabular}
}
\caption[Tokenized BLEU on newstest2014]{{\bf Tokenized BLEU on newstest2014} --  Translation results of various systems which differ in terms of: (a) the architecture, (b) the size of the vocabulary used, and (c) the training corpus, either using the full WMT'14 corpus of 36M sentence pairs or a subset of it with 12M pairs. 
We highlight the performance of our best system in bolded text and state the improvements obtained by our technique of handling rare words (namely, the PosUnk model). Notice that, for a given vocabulary size, the more accurate systems achieve a greater improvement from the post-processing step.  This is the case because the more accurate models are able to pin-point the origin of an unknown
word with greater accuracy, making the post-processing more useful.
}
\label{t:results}
\end{table*}


It is interesting to observe that our approach is more useful for ensemble models as compared to the individual ones. 
This is because the usefulness of the PosUnk model directly
depends on the ability of the NMT to correctly locate, for a given OOV target word, its corresponding word in the source sentence.  An ensemble of large models identifies these source words with greater accuracy.  This is why for the same vocabulary size, better models obtain a greater performance gain our post-processing step. 
Except for the very recent work of \newcite{jean15} that employs a similar unknown treatment strategy\footnote{Their unknown replacement method and ours both track the locations of target unknown words and use a word dictionary to post-process the translation. However, the mechanism used to achieve the ``tracking'' behavior is different. \newcite{jean15}'s uses the attentional mechanism to track the origins of all target words, not just the unknown ones. In contrast, we only focus on tracking unknown words using unsupervised alignments. Our method can be easily applied to any sequence-to-sequence models since we treat any model as a blackbox and manipulate only at the input and output levels.} as ours, our best result of \bestbleuunk{} BLEU outperforms all other NMT systems by a 
arge margin, and 
%in particular, it outperforms the current best NMT system \cite{sutskever14} by \unkimpilya{} BLEU points.
more importanly, our system has established a new record on the WMT'14 English to French translation.

