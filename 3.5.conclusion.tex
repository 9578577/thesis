I have shown that a simple alignment-based technique can mitigate and even
overcome one of the main weaknesses of current NMT systems, which is
their inability to translate words that are not in their vocabulary.  
A key advantage of my technique is the fact that it is applicable to any NMT system and not
only to the deep LSTM model of \newcite{sutskever14}. At the time of this work, in 2014-2015, a technique
like mine is likely necessary if an NMT system is to achieve state-of-the-art performance
on machine translation.

I have demonstrated empirically that on the WMT'14 English-French translation task, my technique yields a 
consistent and substantial improvement of up to \bestunkimp{} BLEU points over various NMT systems of different architectures. 
Most importantly, with \bestbleuunk{} BLEU points, I have established the first NMT system that outperformed 
the best MT system on a WMT'14 contest dataset.

I will now switch gear to address a different problem in NMT,
that is the difficulty in translating long sentences. However, I will return back
to the topic of rare and unknown words in Chapter 5 to present an even better treatment to that problem.

